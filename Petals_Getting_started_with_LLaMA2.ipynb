{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashambkr/Petals_Llama2/blob/main/Petals_Getting_started_with_LLaMA2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "<img src=\"https://camo.githubusercontent.com/473dd9f992924d27457650251786464f72e54121ac6e9210add0f483ca849277/68747470733a2f2f692e696d6775722e636f6d2f3765523750616e2e706e67\" width=\"40%\">  \n",
        "</div>\n",
        "\n",
        "# Getting started with Petals\n",
        "\n",
        "This notebook will guide you through the basics of Petals &mdash; a system for inference and fine-tuning 100B+ language models without the need to have high-end GPUs. With Petals, you can join compute resources with other people over the Internet and run large language models such as LLaMA, Guanaco, or BLOOM right from your desktop computer or Google Colab.\n",
        "\n",
        "üí¨ If you meet any issues while running this notebook, let us know in the **[#running-a-client](https://discord.gg/J29mCBNBvm)** channel of our Discord!\n",
        "\n",
        "So, let's get started! First, let's install [the Petals package](https://github.com/bigscience-workshop/petals):"
      ],
      "metadata": {
        "id": "VsXHWJLuowcn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pBC52TF3LVY1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b04fbcb4-6e6d-4d58-b5e4-f2bf399fdad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: petals in /usr/local/lib/python3.10/dist-packages (2.0.0.post3)\n",
            "Requirement already satisfied: torch>=1.12 in /usr/local/lib/python3.10/dist-packages (from petals) (2.0.1+cu118)\n",
            "Requirement already satisfied: bitsandbytes==0.40.1.post1 in /usr/local/lib/python3.10/dist-packages (from petals) (0.40.1.post1)\n",
            "Requirement already satisfied: accelerate<0.21.0,>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from petals) (0.20.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from petals) (0.16.4)\n",
            "Requirement already satisfied: tokenizers>=0.13.3 in /usr/local/lib/python3.10/dist-packages (from petals) (0.13.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from petals) (4.31.0)\n",
            "Requirement already satisfied: speedtest-cli==2.1.3 in /usr/local/lib/python3.10/dist-packages (from petals) (2.1.3)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from petals) (1.10.11)\n",
            "Requirement already satisfied: hivemind==1.1.8 in /usr/local/lib/python3.10/dist-packages (from petals) (1.1.8)\n",
            "Requirement already satisfied: tensor-parallel==1.0.23 in /usr/local/lib/python3.10/dist-packages (from petals) (1.0.23)\n",
            "Requirement already satisfied: humanfriendly in /usr/local/lib/python3.10/dist-packages (from petals) (10.0)\n",
            "Requirement already satisfied: async-timeout>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from petals) (4.0.2)\n",
            "Requirement already satisfied: cpufeature>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from petals) (0.2.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from petals) (23.1)\n",
            "Requirement already satisfied: sentencepiece>=0.1.99 in /usr/local/lib/python3.10/dist-packages (from petals) (0.1.99)\n",
            "Requirement already satisfied: peft>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from petals) (0.4.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from petals) (0.3.1)\n",
            "Requirement already satisfied: Dijkstar>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from petals) (2.6.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.8->petals) (6.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.8->petals) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.8->petals) (1.10.1)\n",
            "Requirement already satisfied: prefetch-generator>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.8->petals) (1.0.3)\n",
            "Requirement already satisfied: msgpack>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.8->petals) (1.0.5)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.8->petals) (2.4.0)\n",
            "Requirement already satisfied: uvloop>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.8->petals) (0.17.0)\n",
            "Requirement already satisfied: grpcio-tools>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.8->petals) (1.48.2)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.8->petals) (3.20.3)\n",
            "Requirement already satisfied: configargparse>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.8->petals) (1.5.5)\n",
            "Requirement already satisfied: multiaddr>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.8->petals) (0.0.9)\n",
            "Requirement already satisfied: pymultihash>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.8->petals) (0.8.2)\n",
            "Requirement already satisfied: cryptography>=3.4.6 in /usr/lib/python3/dist-packages (from hivemind==1.1.8->petals) (3.4.8)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate<0.21.0,>=0.20.3->petals) (5.9.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from Dijkstar>=2.6.0->petals) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.1->petals) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.1->petals) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.1->petals) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.1->petals) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.1->petals) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->petals) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->petals) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->petals) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->petals) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.12->petals) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.12->petals) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.31.0->petals) (2022.10.31)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.33.2->hivemind==1.1.8->petals) (1.56.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.33.2->hivemind==1.1.8->petals) (67.7.2)\n",
            "Requirement already satisfied: varint in /usr/local/lib/python3.10/dist-packages (from multiaddr>=0.0.9->hivemind==1.1.8->petals) (1.0.2)\n",
            "Requirement already satisfied: base58 in /usr/local/lib/python3.10/dist-packages (from multiaddr>=0.0.9->hivemind==1.1.8->petals) (2.1.1)\n",
            "Requirement already satisfied: netaddr in /usr/local/lib/python3.10/dist-packages (from multiaddr>=0.0.9->hivemind==1.1.8->petals) (0.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12->petals) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0.0,>=0.11.1->petals) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0.0,>=0.11.1->petals) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0.0,>=0.11.1->petals) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0.0,>=0.11.1->petals) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12->petals) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install petals"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ü¶ô **Want to run LLaMA 2?**\n",
        "\n",
        "1. Request access to its weights &mdash; first on the [Meta AI website](https://ai.meta.com/resources/models-and-libraries/llama-downloads/), then at ü§ó [Model Hub](https://huggingface.co/meta-llama/Llama-2-70b-hf) (make sure to use the same email).\n",
        "2. Create an access token [here](https://huggingface.co/settings/tokens).\n",
        "3. Run this command before calling `AutoTokenizer.from_pretrained(...)`:\n",
        "\n",
        "    `!huggingface-cli login --token YOUR_TOKEN_HERE`\n",
        "\n",
        "üìã **Friendly reminder.** This Colab is provided for demo purposes. If you want to use these models in your own projects, make sure you follow their terms of use (see [LLaMA](https://bit.ly/llama-license) and [LLaMA 2](https://bit.ly/llama2-license) licenses) and have an approved access to their weights."
      ],
      "metadata": {
        "id": "JhKyusDDovS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token YOUR_TOKEN_HERE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOPo1NfQUdqr",
        "outputId": "e6750eab-659b-4ca2-d1c5-feefba799f4b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the distributed model üöÄ\n",
        "\n",
        "Let's start with the easiest task &mdash; creating a distributed model and using it for generating text. This machine will download a small part of the model weights and rely on other computers in the network to run the rest of the model.\n",
        "\n",
        "The Petals interface is similar to the ü§ó [Transformers](https://github.com/huggingface/transformers) library &mdash; it feels like you're working with a local model even though parts of it are hosted remotely. We suggest to start with the \"classic\" [LLaMA-65B](https://github.com/facebookresearch/llama/blob/llama_v1/MODEL_CARD.md), but you can also use [LLaMA 2 (70B)](https://huggingface.co/meta-llama/Llama-2-70b-hf) if you have access to it (see below)."
      ],
      "metadata": {
        "id": "yEbot-oEXdpw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2uuX1IMLLotQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "3029405d07c24fb39615de950545ca42",
            "3dbf711bd8fb4e1eb505be14238ea897",
            "3acca3897273493998592927946412bd",
            "de87f2b45c5e476796d2ab29574b1a2f",
            "d527804b6c1a4b59a8b64e64c05cff9c",
            "e2e3914fb5d44722835b5d6b41af56ab",
            "e89299e333c74c0bac4c47993d42e5a8",
            "0f6010fe330c463593d6c1d4454a21d7",
            "5d8f34531b6d4d2ba0ea5a424821d6bf",
            "720d3f2daf05468b8469cbf0ca58cf6d",
            "23c58fc1e5524734b5558f6388ffa817"
          ]
        },
        "outputId": "701fb453-8b6d-4efe-c4ab-562ae270ff8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Jul 21 18:23:23.816 [\u001b[1m\u001b[34mINFO\u001b[0m] Make sure you follow the LLaMA's terms of use: https://bit.ly/llama2-license for LLaMA 2, https://bit.ly/llama-license for LLaMA 1\n",
            "Jul 21 18:23:23.821 [\u001b[1m\u001b[34mINFO\u001b[0m] Using DHT prefix: Llama-2-70b-chat-hf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3029405d07c24fb39615de950545ca42"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from petals import AutoDistributedModelForCausalLM\n",
        "\n",
        "model_name = \"meta-llama/Llama-2-70b-chat-hf\"\n",
        "# You could also use \"meta-llama/Llama-2-70b-hf\", \"enoch/llama-65b-hf\", or\n",
        "# \"bigscience/bloom\" - basically, any Hugging Face Hub repo with a supported model architecture\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False, add_bos_token=False)\n",
        "model = AutoDistributedModelForCausalLM.from_pretrained(model_name)\n",
        "model = model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úçÔ∏è How to generate text?\n",
        "\n",
        "Let's try to generate something by calling __`model.generate()`__ method.\n",
        "\n",
        "The first call to this method takes a few seconds to connect to the Petals swarm. Once we do that, you should expect generation speed of up to **5-6 tokens/sec**. If you don't have enough GPU memory to host the entire model, this is much faster than what you get with other methods, such as offloading or running the model on CPU."
      ],
      "metadata": {
        "id": "zhyUxv13sfKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer('generate a poem on indian food', return_tensors=\"pt\")[\"input_ids\"].cuda()\n",
        "outputs = model.generate(inputs, max_new_tokens=100)\n",
        "print(tokenizer.decode(outputs[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s1IrE1H8wwr",
        "outputId": "51c49d07-dc21-4fa1-df70-1549be6f2c84"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Jul 21 18:23:50.594 [\u001b[1m\u001b[34mINFO\u001b[0m] Route found: 0:32 via ‚Ä¶UpunUJ => 32:33 via ‚Ä¶dU8vhr => 33:35 via ‚Ä¶UpunUJ => 35:40 via ‚Ä¶dU8vhr => 40:80 via ‚Ä¶pmFgLT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generate a poem on indian food.\n",
            "\n",
            "Indian food, a symphony of flavors,\n",
            "A feast for the senses, a culinary delight.\n",
            "From spicy curries to creamy kormas,\n",
            "A journey of taste, a treat for the palate.\n",
            "\n",
            "The aroma of basmati, a fragrant delight,\n",
            "The flavors of cardamom, a sweet and savory blend.\n",
            "The richness of ghee, a buttery\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `model.generate()` method runs **greedy** generation by default. However, you can use other generation methods like **top-p/top-k sampling** or **beam search** (you'll see an example in a bit), or even implement your own.\n",
        "\n",
        "üîè **Note:** Your data is processed by other people in the public swarm. Learn more about privacy [here](https://github.com/bigscience-workshop/petals/wiki/Security,-privacy,-and-AI-safety). For sensitive data, you can set up a [private swarm](https://github.com/bigscience-workshop/petals/wiki/Launch-your-own-swarm) among people you trust."
      ],
      "metadata": {
        "id": "02d0BDEAuUFQ"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3029405d07c24fb39615de950545ca42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3dbf711bd8fb4e1eb505be14238ea897",
              "IPY_MODEL_3acca3897273493998592927946412bd",
              "IPY_MODEL_de87f2b45c5e476796d2ab29574b1a2f"
            ],
            "layout": "IPY_MODEL_d527804b6c1a4b59a8b64e64c05cff9c"
          }
        },
        "3dbf711bd8fb4e1eb505be14238ea897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2e3914fb5d44722835b5d6b41af56ab",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e89299e333c74c0bac4c47993d42e5a8",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "3acca3897273493998592927946412bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f6010fe330c463593d6c1d4454a21d7",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d8f34531b6d4d2ba0ea5a424821d6bf",
            "value": 3
          }
        },
        "de87f2b45c5e476796d2ab29574b1a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_720d3f2daf05468b8469cbf0ca58cf6d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_23c58fc1e5524734b5558f6388ffa817",
            "value": " 3/3 [00:01&lt;00:00,  2.20it/s]"
          }
        },
        "d527804b6c1a4b59a8b64e64c05cff9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2e3914fb5d44722835b5d6b41af56ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e89299e333c74c0bac4c47993d42e5a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f6010fe330c463593d6c1d4454a21d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d8f34531b6d4d2ba0ea5a424821d6bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "720d3f2daf05468b8469cbf0ca58cf6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23c58fc1e5524734b5558f6388ffa817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}